{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.backends.backend_pdf\n",
    "import matplotlib.transforms as mtransforms\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def smape(A, F):\n",
    "    if any(x==0 for x in (np.abs(A) + np.abs(F))):\n",
    "        return -1\n",
    "    else:\n",
    "        return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function, that will transform this to big dataframe and save to csv\n",
    "def print_to_csv(y_predicted,y_true,last_rpd,predicted_rpd,method_name = \"test\"):\n",
    "    needed_values = [(3,0),(4,0),(5,0),(6,0),(7,0),(8,0),(8,1),(8,2),(8,3),(2,4),(3,4),(4,4),(5,4),(6,4),(7,4),(8,4),(8,5),(8,7),(1,6),(2,6),(3,6),(4,6),(5,6),(6,6),(7,6),(8,6),(8,8),(0,9),(1,9),(2,9),(3,9),(4,9),(5,9),(6,9),(7,9),(8,9)]\n",
    "    exp = pd.DataFrame(columns=['item','rpd','future_flag','true_value','predicted','method'])\n",
    "    for it in y_predicted.keys():\n",
    "        true_values = []\n",
    "        predicted_values = []\n",
    "        for x in needed_values:\n",
    "            true_values.append(y_true[it].values[x[0]][x[1]])\n",
    "            predicted_values.append(y_predicted[it][x[1]][x[0]])\n",
    "        #create row of \n",
    "        row_of_prediction = [y_true[it]]\n",
    "        i = 0\n",
    "        for ff in range(0,4):\n",
    "            for rpd in range(predicted_rpd,last_rpd+1):\n",
    "                d1 = pd.DataFrame([[it,rpd,ff,true_values[i],predicted_values[i],method_name]], columns=['item','rpd','future_flag','true_value','predicted','method'])\n",
    "                i+=1\n",
    "                exp = exp.append(d1)\n",
    "    exp = exp.set_index([\"item\", \"rpd\", \"future_flag\"]).sort_index()\n",
    "    exp.to_csv(method_name+'.csv')\n",
    "    return exp.drop(columns = [\"method\",\"predicted\"]).reset_index(),exp.drop(columns = [\"method\",\"true_value\"]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(plot_array,message = \"\",close = 1):\n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(\"plots/\"+message+\".pdf\")\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        smape_res = smape_(plot_array[i][0], plot_array[i][1], mean = False)\n",
    "        fig, ax = plt.subplots(figsize = (5, 6))\n",
    "        plt.hist(smape_res)\n",
    "        plt.axvline(smape_res.mean(), color='r', linestyle='dashed', linewidth=1)\n",
    "        ax.set_xlabel('SMAPE, %. '+message+' Flag = '+str(i)+'.')\n",
    "        plt.savefig('plots/Hist. '+message+' Flag = '+str(i)+'.jpg',dpi =300)\n",
    "        ax.annotate('Mean SMAPE = '+str(int(smape_res.mean()))+\" %\",\n",
    "            xy=(smape_res.mean(), ax.get_ylim()[1]), xytext=(smape_res.mean()+(ax.get_xlim()[1]-ax.get_xlim()[0])*0.07, ax.get_ylim()[1]*1.015),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.1),\n",
    "            annotation_clip=False)\n",
    "        pdf.savefig(ax.figure,dpi = 300)\n",
    "        if (close ==1):\n",
    "            plt.close()\n",
    "                        \n",
    "    for i in range(0,4):\n",
    "        test_flat = plot_array[i][0].values.flatten()\n",
    "        predicted_flat = plot_array[i][1].values.flatten()\n",
    "        fig, ax = plt.subplots(figsize = (5, 6))\n",
    "        plt.scatter(predicted_flat, test_flat)\n",
    "        ax.set_xlabel('Predicted values')\n",
    "        ax.set_ylabel('True values')\n",
    "        line = mlines.Line2D([0, 1], [0, 1],linewidth = 1.0, color='black',linestyle='dashed')\n",
    "        transform = ax.transAxes\n",
    "        line.set_transform(transform)\n",
    "        ax.add_line(line)\n",
    "        ax.set_xscale('symlog')\n",
    "        ax.set_yscale('symlog')\n",
    "        ax.set_title(message+' Flag = '+str(i)+'.')\n",
    "        plt.savefig('plots/Scatter. '+message+' Flag = '+str(i)+'.jpg',dpi =300)            \n",
    "        pdf.savefig(ax.figure,dpi = 300)\n",
    "        if (close ==1):\n",
    "            plt.close()    \n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, df_0, future_flag):\n",
    "    items = df.item.unique()\n",
    "    df = df[df['future_flag'] == future_flag]\n",
    "    df = df.groupby(['rpd', 'item']).sum().reset_index().drop('future_flag', axis = 1)\n",
    "    for item in items:\n",
    "        tmp = df[df['item'] == item].drop('item', axis = 1)\n",
    "        tmp.columns = ['rpd', str(item)]\n",
    "        df_0 = df_0.merge(tmp, on = 'rpd', how = 'left')\n",
    "    df_0.set_index('rpd', inplace = True)\n",
    "    return df_0\n",
    "def create_dataframes_for_plots(df):\n",
    "    df_0 = pd.DataFrame(df.rpd.unique())\n",
    "    df_0.columns = ['rpd']\n",
    "    df_0.sort_values(by = 'rpd', ascending = True, inplace = True)\n",
    "    df_flag_0 = create_dataset(df, df_0, 0) # dataset for future_flag = 0 \n",
    "    df_flag_1 = create_dataset(df, df_0, 1) # dataset for future_flag = 1\n",
    "    df_flag_2 = create_dataset(df, df_0, 2) # dataset for future_flag = 2 \n",
    "    df_flag_3 = create_dataset(df, df_0, 3) # dataset for future_flag = 3\n",
    "    return df_flag_0,df_flag_1,df_flag_2,df_flag_3\n",
    "def smape_(y_true, y_pred, mean = True):\n",
    "    smape = 2 * np.sum(np.abs(y_pred-y_true) / np.abs(y_true + y_pred), axis = 0)*100/len(y_pred)\n",
    "    if mean == True:\n",
    "        smape = smape.mean()\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating exp_y,exp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Xy(data, n_order=1):\n",
    "    n_ahead = data.shape[1]\n",
    "    data_X = pd.concat([\n",
    "        data.shift(-h).rename(columns=f\"{h}-{{}}\".format).iloc[:, h:]\n",
    "        for h in range(n_ahead)\n",
    "    ], axis=1)\n",
    "\n",
    "    # get q^h_{:t} -- autoregressive features (known by t-h-1)\n",
    "    if n_order == 1:\n",
    "        data_X = data_X.shift(1)\n",
    "\n",
    "    else:\n",
    "        data_X = pd.concat([\n",
    "            data_X.shift(lag).rename(f\"{lag}-{{}}\".format, axis=1)\n",
    "            for lag in range(1, n_order + 1)\n",
    "        ], axis=1)\n",
    "    # end if\n",
    "\n",
    "    # get (q^h_{t+s})_{h < s, s=1..4} -- current target (known at t+1, t+2, t+3 and t+4)\n",
    "    data_y = pd.concat([\n",
    "        data.shift(-h).rename(columns=f\"{h+1}-{{}}\".format).iloc[:, :h+1]\n",
    "        for h in range(n_ahead)\n",
    "    ], axis=1)\n",
    "\n",
    "    # return data_X, data_y\n",
    "\n",
    "    # X and y are already properly shifted and thus the NaNs can just be dropped\n",
    "    data_X, data_y = data_X.dropna(), data_y.dropna()\n",
    "    return data_X.align(data_y, join=\"inner\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y(df,first_rpd=1,last_rpd=45,predicted_rpd=37):\n",
    "    \"\"\"first_rpd: int\n",
    "        Data in dataset starts with this rpd. (1 for dataset 1-2;108 for dataset 3)\n",
    "    last_rpd: int\n",
    "        Data in dataset ends with this rpd. (45 for dataset 1-2;151 for dataset 3)\n",
    "    predicted_rpd:int\n",
    "        Algorithm will start predicting values starting from this rpd. (37 for dataset 1-2;143 for dataset 3) \"\"\"\n",
    "    df = df.set_index([\"item\", \"rpd\", \"future_flag\"]).sort_index()\n",
    "    all_items = set(df.index.get_level_values('item'))\n",
    "    y_predicted = defaultdict()\n",
    "    exp_X = pd.DataFrame(columns=['item','rpd',' 0-0',' 0-1',' 0-2',' 0-3',' 1-1',' 1-2',' 1-3',' 2-2',' 2-3',' 3-3']) \n",
    "    exp_Y = pd.DataFrame(columns=['item','rpd',' 1-0',' 2-0',' 2-1',' 3-0',' 3-1',' 3-2',' 4-0',' 4-1',' 4-2',' 4-3'])  \n",
    "    y_quantity_item = defaultdict()\n",
    "    for it in all_items:\n",
    "        item_ = df.query('item == '+str(it))\n",
    "        #It was stated that skip all items, for which # of rpd<38  (around 120 from 720 items)\n",
    "        if item_.groupby('rpd').ngroups!=(last_rpd-first_rpd+1):\n",
    "            continue\n",
    "        demand_total_item = item_[\"quantity_ecd\"].unstack(fill_value=0)\n",
    "        qty_total_item = demand_total_item.unstack(\"item\", fill_value=0.)\n",
    "        if (item_.groupby('future_flag').ngroups==1):\n",
    "            qty_total_item[1]=0\n",
    "            qty_total_item[2]=0\n",
    "            qty_total_item[3]=0\n",
    "        else:\n",
    "            if (item_.groupby('future_flag').ngroups==2):\n",
    "                qty_total_item[2]=0\n",
    "                qty_total_item[3]=0\n",
    "            else:\n",
    "                if (item_.groupby('future_flag').ngroups==3):\n",
    "                    qty_total_item[3]=0           \n",
    "        t = make_Xy(qty_total_item)\n",
    "        X_quantity_item = t[0].loc[first_rpd:last_rpd,:]\n",
    "        Y_quantity_item = t[1].loc[first_rpd:last_rpd,:]\n",
    "        X_quantity_item= X_quantity_item.reset_index()\n",
    "        X_quantity_item.insert(0, 'item', it)\n",
    "        Y_quantity_item= Y_quantity_item.reset_index()\n",
    "        Y_quantity_item.insert(0, 'item', it)\n",
    "        exp_X = exp_X.append(pd.DataFrame(X_quantity_item.values,columns = ['item','rpd',' 0-0',' 0-1',' 0-2',' 0-3',' 1-1',' 1-2',' 1-3',' 2-2',' 2-3',' 3-3']))\n",
    "        exp_Y = exp_Y.append(pd.DataFrame(Y_quantity_item.values,columns = ['item','rpd',' 1-0',' 2-0',' 2-1',' 3-0',' 3-1',' 3-2',' 4-0',' 4-1',' 4-2',' 4-3']))\n",
    "    exp_X = exp_X.applymap(int)\n",
    "    exp_Y = exp_Y.applymap(int)\n",
    "    return exp_X,exp_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_all_items_fit(exp_X_trunc,exp_Y_trunc,regrr,transformation,first_rpd,last_rpd,predicted_rpd):\n",
    "    y_predicted = defaultdict()\n",
    "    exp_Y_trunc = exp_Y_trunc.reindex(columns=['rpd','item',' 1-0',' 2-0',' 3-0',' 4-0',' 2-1',' 3-1',' 3-2',' 4-1',' 4-2',' 4-3'])\n",
    "    y_true = defaultdict()\n",
    "    for it in set(exp_X_trunc.item):\n",
    "        y_predicted[it] = [[],[],[],[],[],[],[],[],[],[]]\n",
    "        y_true[it] = [[],[],[],[],[],[],[],[],[],[]]\n",
    "    for i in range(predicted_rpd-4,last_rpd):       \n",
    "        if (transformation==1):\n",
    "            scaler = MinMaxScaler() \n",
    "        X = exp_X_trunc.loc[exp_X_trunc['rpd'].isin(list(range(first_rpd,i+1)))].iloc[:,2:12]\n",
    "        for ii in range(1,11):\n",
    "            regr = regrr\n",
    "            if (transformation==1):\n",
    "                scaler_y = MinMaxScaler() ##\n",
    "            Y = exp_Y_trunc.loc[exp_Y_trunc['rpd'].isin(list(range(first_rpd,i+1)))].iloc[:,ii+1] \n",
    "            if (transformation==1):\n",
    "                Y = scaler_y.fit_transform( np.array([list(map(float,Y))]).transpose()) ##\n",
    "                X_scaled = scaler.fit_transform(X) ##\n",
    "            if (transformation==0):\n",
    "                regr.fit(X,Y)\n",
    "            if (transformation==1):\n",
    "                regr.fit(X_scaled,np.array(Y).ravel())\n",
    "            if (transformation==2):\n",
    "                regr.fit(np.log1p(X),np.log1p(Y))\n",
    "            for it in set(exp_X_trunc.item):\n",
    "                X_test = exp_X_trunc.loc[exp_X_trunc['rpd'].isin(list(range(i+1,i+2)))]\n",
    "                X_test = X_test.loc[X_test['item']==it].iloc[:,2:12]\n",
    "                if (X_test.size==0):\n",
    "                    continue\n",
    "                if (transformation==0):\n",
    "                    y_predicted[it][ii-1].append(regr.predict(X_test)[0])\n",
    "                if (transformation==1):\n",
    "                    scaled_prediction = regr.predict( scaler.transform(X_test))[0]\n",
    "                    y_predicted[it][ii-1].append(  scaler_y.inverse_transform(scaled_prediction)[0][0])\n",
    "                if (transformation==2):\n",
    "                    y_predicted[it][ii-1].append(  np.expm1 (regr.predict(np.log1p(X_test))[0]))              \n",
    "                true_ = exp_Y_trunc.loc[exp_Y_trunc['rpd'].isin(list(range(i+1,i+2)))]\n",
    "                true_ = true_.loc[true_['item']==it].iloc[:,ii+1].values[0]\n",
    "                y_true[it][ii-1].append(true_)\n",
    "    for x in y_predicted.keys():\n",
    "        y_predicted[x] = pd.DataFrame(np.array(y_predicted[x]).clip(min=0).transpose())\n",
    "        y_true[x] = pd.DataFrame(np.array(y_true[x]).transpose()).applymap(float)\n",
    "    return y_predicted,y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_item_by_item_fit(exp_X_trunc,exp_Y_trunc,regrr,transformation,first_rpd,last_rpd,predicted_rpd):\n",
    "    y_predicted = defaultdict()\n",
    "    exp_Y_trunc = exp_Y_trunc.reindex(columns=['rpd','item',' 1-0',' 2-0',' 3-0',' 4-0',' 2-1',' 3-1',' 3-2',' 4-1',' 4-2',' 4-3'])\n",
    "    y_true = defaultdict()\n",
    "    for it in set(exp_X_trunc.item):\n",
    "        y_predicted[it] = [[],[],[],[],[],[],[],[],[],[]]\n",
    "        y_true[it] = [[],[],[],[],[],[],[],[],[],[]]\n",
    "    for i in range(predicted_rpd-4,last_rpd):  \n",
    "        for ii in range(1,11):\n",
    "            for it in set(exp_X_trunc.item):\n",
    "                regr = regrr\n",
    "                X = exp_X_trunc.loc[exp_X_trunc['rpd'].isin(list(range(first_rpd,i+1)))]\n",
    "                X = X.loc[X['item']==it].iloc[:,2:12]\n",
    "                Y = exp_Y_trunc.loc[exp_Y_trunc['rpd'].isin(list(range(first_rpd,i+1)))]\n",
    "                Y = Y.loc[Y['item']==it].iloc[:,ii+1]\n",
    "                if (transformation==0):\n",
    "                    regr.fit(X,Y)          \n",
    "                    X_test = exp_X_trunc.loc[exp_X_trunc['rpd'].isin(list(range(i+1,i+2)))]\n",
    "                    X_test = X_test.loc[X_test['item']==it].iloc[:,2:12]\n",
    "                    if (X_test.size==0):\n",
    "                        continue\n",
    "                    y_predicted[it][ii-1].append(regr.predict(X_test)[0])\n",
    "                if (transformation==1):\n",
    "                    scaler = MinMaxScaler() \n",
    "                    scaler_y = MinMaxScaler()\n",
    "                    Y = scaler_y.fit_transform( np.array([list(map(float,Y))]).transpose())\n",
    "                    X_scaled = scaler.fit_transform(X) \n",
    "                    regr.fit(X_scaled,np.array(Y).ravel())\n",
    "                    X_test = exp_X_trunc.loc[exp_X_trunc['rpd'].isin(list(range(i+1,i+2)))]\n",
    "                    X_test = X_test.loc[X_test['item']==it].iloc[:,2:12]\n",
    "                    if (X_test.size==0):\n",
    "                        continue\n",
    "                    scaled_prediction = regr.predict( scaler.transform(X_test))[0]\n",
    "                    y_predicted[it][ii-1].append(  scaler_y.inverse_transform(scaled_prediction)[0][0])\n",
    "                if (transformation==2):\n",
    "                    regr.fit(np.log1p(X),np.log1p(Y))\n",
    "                    X_test = exp_X_trunc.loc[exp_X_trunc['rpd'].isin(list(range(i+1,i+2)))]\n",
    "                    X_test = X_test.loc[X_test['item']==it].iloc[:,2:12]\n",
    "                    if (X_test.size==0):\n",
    "                        continue\n",
    "                    y_predicted[it][ii-1].append(  np.expm1 (regr.predict(np.log1p(X_test))[0]))                    \n",
    "                true_ = exp_Y_trunc.loc[exp_Y_trunc['rpd'].isin(list(range(i+1,i+2)))]\n",
    "                true_ = true_.loc[true_['item']==it].iloc[:,ii+1].values[0]\n",
    "                y_true[it][ii-1].append(true_)\n",
    "    for x in y_predicted.keys():\n",
    "        y_predicted[x] = pd.DataFrame(np.array(y_predicted[x]).clip(min=0).transpose())\n",
    "        y_true[x] = pd.DataFrame(np.array(y_true[x]).transpose()).applymap(float)\n",
    "    return y_predicted,y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(exp_X,exp_Y,regr,fitting=0,transformation=0,first_rpd = 1, last_rpd = 45, predicted_rpd = 37,name=\"\"):\n",
    "    \"\"\" Predicts values using matrix feeding\n",
    "    exp_X : DataFrame of features\n",
    "        Should be generated using create_X_y function.\n",
    "    exp_Y: DataFrame of targets\n",
    "        Should be generated using create_X_y function.\n",
    "    regr: \n",
    "        Regressor with sklearn api.\n",
    "    fitting: int\n",
    "        Type of fitting: 0 - fitting item by item, 1 - fit all items at once.\n",
    "    transformation: int\n",
    "        Type of transformation: 0 - no transformation, 1 - MinMax scaling, 2 - log transformation.\n",
    "    name: string\n",
    "        Name of the output file and. The default one will combine parameters.\n",
    "    first_rpd: int\n",
    "        Data in dataset starts with this rpd. (1 for dataset 1-2;108 for dataset 3)\n",
    "    last_rpd: int\n",
    "        Data in dataset ends with this rpd. (45 for dataset 1-2;151 for dataset 3)\n",
    "    predicted_rpd:int\n",
    "        Algorithm will start predict values starting from this rpd. (37 for dataset 1-2;143 for dataset 3) \"\"\"\n",
    "    if (name==\"\"):\n",
    "        name = str(regr)[:10]+str(fitting)+str(transformation)\n",
    "    # Predicts values\n",
    "    if (fitting==0):\n",
    "        y_predicted, y_true= prediction_item_by_item_fit(exp_X,exp_Y,regr,transformation,first_rpd,last_rpd,predicted_rpd)\n",
    "    if (fitting==1):\n",
    "        y_predicted, y_true= prediction_all_items_fit(exp_X,exp_Y,regr,transformation,first_rpd,last_rpd,predicted_rpd)\n",
    "    # Prints to csv\n",
    "    true_,pred_  = print_to_csv(y_predicted,y_true,last_rpd,predicted_rpd,name)\n",
    "    # Plotting\n",
    "    true_0,true_1,true_2,true_3 = create_dataframes_for_plots(true_)\n",
    "    pred_0,pred_1,pred_2,pred_3= create_dataframes_for_plots(pred_)\n",
    "    plot_array = [(true_0,pred_0),(true_1,pred_1),(true_2,pred_2),(true_3,pred_3)]\n",
    "    plot_hist(plot_array, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input/demand_encode_out.csv\", header=0, index_col=None)\n",
    "exp_X,exp_Y = create_X_y(df,1,45,37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(exp_X,exp_Y,MLPRegressor(activation= 'tanh', hidden_layer_sizes= (20,), solver= 'lbfgs'),\n",
    "           fitting = 0,transformation = 1,\n",
    "           first_rpd = 1,last_rpd =45,predicted_rpd = 37,\n",
    "           name = \"NN;item_by_item_fit;minmax;dataset1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input/demand_out_encoded_stage_3.csv\", header=0, index_col=None)\n",
    "exp_X,exp_Y = create_X_y(df,108,151,143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(exp_X,exp_Y,MLPRegressor(activation= 'tanh', hidden_layer_sizes= (20,), solver= 'lbfgs'),\n",
    "           fitting = 1,transformation = 2,\n",
    "           first_rpd = 108,last_rpd =151,predicted_rpd = 143,\n",
    "           name = \"NN;all_fit;log;dataset3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
